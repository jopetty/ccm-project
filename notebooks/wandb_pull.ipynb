{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_path = Path(os.getcwd())\n",
    "env_path = curr_path.parent.absolute() / \".env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(projects=[\"ccm_project\"], entity=\"jpetty\"):\n",
    "\n",
    "    api = wandb.Api(api_key=os.environ[\"WANDB_API_KEY\"])\n",
    "\n",
    "    runs_dfs = []\n",
    "    for project in projects:\n",
    "\n",
    "        runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "        summary_list, config_list, name_list = [], [], []\n",
    "        run_hashes = []\n",
    "        for run in tqdm(runs):\n",
    "            # .summary contains output keys/values for\n",
    "            # metrics such as accuracy.\n",
    "            #  We call ._json_dict to omit large files\n",
    "            summary_list.append(run.summary._json_dict)\n",
    "\n",
    "            # .config contains the hyperparameters.\n",
    "            #  We remove special values that start with _.\n",
    "            config_list.append(\n",
    "                {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "            )\n",
    "\n",
    "            # .name is the human-readable name of the run.\n",
    "            name_list.append(run.name)\n",
    "            if len(run.logged_artifacts()) > 0:\n",
    "                for table in run.logged_artifacts():\n",
    "                    table_dir = table.download()\n",
    "                    run_hash = Path(table_dir).name\n",
    "                    if \"vocab\" in run_hash:\n",
    "                        run_hashes.append({\"name\": run.name, \"hash\": run_hash})\n",
    "            #   table = run.logged_artifacts()[0]\n",
    "            #   table_dir = table.download()\n",
    "            #   run_hash = Path(table_dir).name\n",
    "            #   print(run_hash)\n",
    "            #   table_name = \"vocab\"\n",
    "            #   table_path = f\"{table_dir}/{table_name}.table.json\"\n",
    "            #   print(table_path)\n",
    "\n",
    "            #   with open(table_path) as file:\n",
    "            #     json_dict = json.load(file)\n",
    "            #     df = pd.DataFrame(json_dict[\"data\"], columns=json_dict[\"columns\"])\n",
    "            #   print(df)\n",
    "            #   raise SystemExit\n",
    "            # run_artifacts = run.logged_artifacts()\n",
    "            # for art in run_artifacts:\n",
    "            #    print(art)\n",
    "            # print(run.summary._json_dict)\n",
    "            # raise SystemExit\n",
    "\n",
    "        runs_df = pd.DataFrame(\n",
    "            {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    "        )\n",
    "\n",
    "        # print(run_hashes)\n",
    "        run_hash_df = pd.DataFrame.from_dict(run_hashes)\n",
    "        # print(run_hash_df)\n",
    "\n",
    "        runs_dfs.append(runs_df)\n",
    "\n",
    "    good_names = [\"colorful-morning-3\"]\n",
    "    runs_dfs = [x for x in runs_dfs if x[\"name\"].isin(good_names).any()]\n",
    "\n",
    "    runs_df = pd.concat(runs_dfs, ignore_index=True)\n",
    "    runs_df = pd.merge(runs_df, run_hash_df, on=\"name\")\n",
    "\n",
    "    summary_df = pd.json_normalize(runs_df[\"summary\"])\n",
    "    config_df = pd.json_normalize(runs_df[\"config\"])\n",
    "\n",
    "    runs_df = pd.concat(\n",
    "        [runs_df.drop([\"summary\", \"config\"], axis=1), summary_df, config_df], axis=1\n",
    "    )\n",
    "\n",
    "    return runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
