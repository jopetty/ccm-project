{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrootutils\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from src.tokenizer_metrics import (\n",
    "    AlignmentWithCDI,\n",
    "    AverageTokenLength,\n",
    "    CorrespondenceWithMorphemes,\n",
    "    SingleTokenizerMetric,\n",
    "    SplitsIntoMorphemes,\n",
    "    SplitsOnSpace,\n",
    "    TokenizerOverlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = path = pyrootutils.find_root(\n",
    "    search_from=os.path.abspath(\"\"), indicator=\".project-root\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TOKENIZERS TO RUN HERE!\n",
    "\n",
    "tokenizers = {}\n",
    "tokenizers[\"BPE 10 splits no retrain\"] = [\n",
    "    Tokenizer.from_file(\n",
    "        str(PROJECT_ROOT / f\"outputs/2024-04-22-144844_30cf/tokenizer_{i}.json\")\n",
    "    )\n",
    "    for i in range(1, 11)\n",
    "]\n",
    "tokenizers[\"BPE 10 splits retrain\"] = [\n",
    "    Tokenizer.from_file(\n",
    "        str(PROJECT_ROOT / f\"outputs/2024-04-22-145055_617e/tokenizer_{i}.json\")\n",
    "    )\n",
    "    for i in range(1, 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitokenizer_metrics = [AlignmentWithCDI, TokenizerOverlap]\n",
    "metric_names = [\n",
    "    tokenizer_metric.__qualname__ for tokenizer_metric in multitokenizer_metrics\n",
    "]\n",
    "scores = {}\n",
    "for tokenizer_type, tokenizer_list in tokenizers.items():\n",
    "    scores[tokenizer_type] = [\n",
    "        metric(tokenizer_list).calculate() for metric in multitokenizer_metrics\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(scores))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "for attribute, measurement in scores.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(\"Scores\")\n",
    "ax.set_title(\"Tokenizer Metrics\")\n",
    "ax.set_xticks(x + width, metric_names)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(metric: dict[str, float], metric_name: str):\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    for tok_type, values in metric.items():\n",
    "        plt.plot(values, label=tok_type)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Tokenizer Iteration\")\n",
    "    plt.title(metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_and_plot(metric_name: SingleTokenizerMetric, **args):\n",
    "    values = {}\n",
    "    for tok_type, tok_list in tokenizers.items():\n",
    "        scores = []\n",
    "        for tok in tok_list:\n",
    "            x = metric_name(tok, **args)\n",
    "            scores.append(x.calculate())\n",
    "        values[tok_type] = scores\n",
    "    plot_comparison(values, metric_name=metric_name.__qualname__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nospace_tokenizers = [\n",
    "    Tokenizer.from_file(\n",
    "        str(PROJECT_ROOT / f\"outputs/2024-05-04-015934_1db9/tokenizer_{i}.json\")\n",
    "    )\n",
    "    for i in range(0, 11)\n",
    "]\n",
    "# percentage of spaces that correspond to token boundaries\n",
    "scores = []\n",
    "for tok in nospace_tokenizers:\n",
    "    x = SplitsOnSpace(tok)\n",
    "    scores.append(x.calculate())\n",
    "plot_comparison({\"no space\": scores}, metric_name=SplitsOnSpace.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of tokenized boundaries that correspond to actual spaces\n",
    "scores = []\n",
    "for tok in nospace_tokenizers:\n",
    "    x = SplitsOnSpace(tok, baseline=\"tokenized\")\n",
    "    scores.append(x.calculate())\n",
    "plot_comparison({\"no space\": scores}, metric_name=SplitsOnSpace.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot(AverageTokenLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot(CorrespondenceWithMorphemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot(SplitsIntoMorphemes, metric=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot(SplitsIntoMorphemes, metric=\"distance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccm_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
